{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import math\n",
    "import time\n",
    "from typing import Tuple\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "try:\n",
    "    import brax\n",
    "except:\n",
    "    !pip install git+https://github.com/google/brax.git@v0.9.2 |tail -n 1\n",
    "    import brax\n",
    "\n",
    "try:\n",
    "    import flax\n",
    "except:\n",
    "    !pip install --no-deps git+https://github.com/google/flax.git@v0.7.4 |tail -n 1\n",
    "    import flax\n",
    "\n",
    "try:\n",
    "    import chex\n",
    "except:\n",
    "    !pip install --no-deps git+https://github.com/deepmind/chex.git@v0.1.83 |tail -n 1\n",
    "    import chex\n",
    "\n",
    "try:\n",
    "    import jumanji\n",
    "except:\n",
    "    !pip install \"jumanji==0.3.1\"\n",
    "    import jumanji\n",
    "\n",
    "try:\n",
    "    import haiku\n",
    "except:\n",
    "    !pip install git+https://github.com/deepmind/dm-haiku.git@v0.0.5 |tail -n 1\n",
    "    import haiku\n",
    "\n",
    "try:\n",
    "    import qdax\n",
    "except:\n",
    "    !pip install --no-deps git+https://github.com/adaptive-intelligent-robotics/QDax@main |tail -n 1\n",
    "    import qdax\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from brax.v1.io import html\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm\n",
    "\n",
    "from qdax import environments\n",
    "from qdax.baselines.pbt import PBTTrainingState\n",
    "from qdax.baselines.td3_pbt import PBTTD3, PBTTD3Config\n",
    "from qdax.core.containers.mapelites_repertoire import compute_cvt_centroids\n",
    "from qdax.core.emitters.pbt_me_emitter import PBTEmitter, PBTEmitterConfig\n",
    "from qdax.core.emitters.pbt_variation_operators import td3_pbt_variation_fn\n",
    "from qdax.core.distributed_map_elites import DistributedMAPElites\n",
    "from qdax.types import RNGKey\n",
    "from qdax.utils.metrics import default_qd_metrics\n",
    "from qdax.utils.plotting import plot_2d_map_elites_repertoire, plot_map_elites_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_platform_name\", \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = jax.devices(\"tpu\")\n",
    "num_devices = len(devices)\n",
    "print(f\"Detected the following {num_devices} device(s): {devices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"anttrap\"\n",
    "\n",
    "seed = 0\n",
    "\n",
    "# TD3 config\n",
    "episode_length = 1000\n",
    "batch_size = 256\n",
    "policy_delay = 2\n",
    "soft_tau_update = 0.005\n",
    "critic_hidden_layer_size = (256, 256)\n",
    "policy_hidden_layer_size = (256, 256)\n",
    "\n",
    "# Emitter config\n",
    "buffer_size = 100000\n",
    "pg_population_size_per_device = 10\n",
    "ga_population_size_per_device = 10\n",
    "num_training_steps = 5000\n",
    "env_batch_size = 250\n",
    "grad_updates_per_step = 1.0\n",
    "iso_sigma = 0.005\n",
    "line_sigma = 0.05\n",
    "\n",
    "fraction_best_to_replace_from = 0.1\n",
    "fraction_to_replace_from_best = 0.2\n",
    "fraction_to_replace_from_samples = 0.4\n",
    "# this fraction is used only for transfer between devices\n",
    "fraction_sort_exchange = 0.1\n",
    "\n",
    "eval_env_batch_size = 1\n",
    "\n",
    "# MAP-Elites config\n",
    "num_init_cvt_samples = 50000\n",
    "num_centroids = 1024\n",
    "log_period = 1\n",
    "num_iterations = 20\n",
    "save_repertoire_freq = 5\n",
    "# num_iterations = 450\n",
    "# save_repertoire_freq = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Initialize environments\n",
    "env = environments.create(\n",
    "    env_name=env_name,\n",
    "    batch_size=env_batch_size * pg_population_size_per_device,\n",
    "    episode_length=episode_length,\n",
    "    auto_reset=True,\n",
    ")\n",
    "\n",
    "eval_env = environments.create(\n",
    "    env_name=env_name,\n",
    "    batch_size=eval_env_batch_size,\n",
    "    episode_length=episode_length,\n",
    "    auto_reset=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bd, max_bd = env.behavior_descriptor_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "key = jax.random.PRNGKey(seed)\n",
    "key, subkey = jax.random.split(key)\n",
    "env_states = jax.jit(env.reset)(rng=subkey)\n",
    "eval_env_first_states = jax.jit(eval_env.reset)(rng=subkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get agent\n",
    "config = PBTTD3Config(\n",
    "    episode_length=episode_length,\n",
    "    batch_size=batch_size,\n",
    "    policy_delay=policy_delay,\n",
    "    soft_tau_update=soft_tau_update,\n",
    "    critic_hidden_layer_size=critic_hidden_layer_size,\n",
    "    policy_hidden_layer_size=policy_hidden_layer_size,\n",
    ")\n",
    "\n",
    "agent = PBTTD3(config=config, action_size=env.action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init emitter\n",
    "emitter_config = PBTEmitterConfig(\n",
    "    buffer_size=buffer_size,\n",
    "    num_training_iterations=num_training_steps // env_batch_size,\n",
    "    env_batch_size=env_batch_size,\n",
    "    grad_updates_per_step=grad_updates_per_step,\n",
    "    pg_population_size_per_device=pg_population_size_per_device,\n",
    "    ga_population_size_per_device=ga_population_size_per_device,\n",
    "    num_devices=num_devices,\n",
    "    fraction_best_to_replace_from=fraction_best_to_replace_from,\n",
    "    fraction_to_replace_from_best=fraction_to_replace_from_best,\n",
    "    fraction_to_replace_from_samples=fraction_to_replace_from_samples,\n",
    "    fraction_sort_exchange=fraction_sort_exchange,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_fn = functools.partial(\n",
    "    td3_pbt_variation_fn, iso_sigma=iso_sigma, line_sigma=line_sigma\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emitter = PBTEmitter(\n",
    "    pbt_agent=agent,\n",
    "    config=emitter_config,\n",
    "    env=env,\n",
    "    variation_fn=variation_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get scoring function\n",
    "bd_extraction_fn = environments.behavior_descriptor_extractor[env_name]\n",
    "eval_policy = agent.get_eval_qd_fn(eval_env, bd_extraction_fn=bd_extraction_fn)\n",
    "\n",
    "\n",
    "def scoring_function(genotypes, random_key):\n",
    "    population_size = jax.tree_leaves(genotypes)[0].shape[0]\n",
    "    first_states = jax.tree_map(\n",
    "        lambda x: jnp.expand_dims(x, axis=0), eval_env_first_states\n",
    "    )\n",
    "    first_states = jax.tree_map(\n",
    "        lambda x: jnp.repeat(x, population_size, axis=0), first_states\n",
    "    )\n",
    "    population_returns, population_bds, _, _ = eval_policy(genotypes, first_states)\n",
    "    return population_returns, population_bds, None, random_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get minimum reward value to make sure qd_score are positive\n",
    "reward_offset = environments.reward_offset[env_name]\n",
    "\n",
    "# Define a metrics function\n",
    "metrics_function = functools.partial(\n",
    "    default_qd_metrics,\n",
    "    qd_offset=reward_offset * episode_length,\n",
    ")\n",
    "\n",
    "# Get the MAP-Elites algorithm\n",
    "map_elites = DistributedMAPElites(\n",
    "    scoring_function=scoring_function,\n",
    "    emitter=emitter,\n",
    "    metrics_function=metrics_function,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "centroids, key = compute_cvt_centroids(\n",
    "    num_descriptors=env.behavior_descriptor_length,\n",
    "    num_init_cvt_samples=num_init_cvt_samples,\n",
    "    num_centroids=num_centroids,\n",
    "    minval=min_bd,\n",
    "    maxval=max_bd,\n",
    "    random_key=key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, *keys = jax.random.split(key, num=1 + num_devices)\n",
    "keys = jnp.stack(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# get the initial training states and replay buffers\n",
    "agent_init_fn = agent.get_init_fn(\n",
    "    population_size=pg_population_size_per_device + ga_population_size_per_device,\n",
    "    action_size=env.action_size,\n",
    "    observation_size=env.observation_size,\n",
    "    buffer_size=buffer_size,\n",
    ")\n",
    "keys, training_states, _ = jax.pmap(agent_init_fn, axis_name=\"p\", devices=devices)(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# empty optimizers states to avoid too heavy repertories\n",
    "training_states = jax.pmap(\n",
    "    jax.vmap(training_states.__class__.empty_optimizers_states),\n",
    "    axis_name=\"p\",\n",
    "    devices=devices,\n",
    ")(training_states)\n",
    "\n",
    "# initialize map-elites\n",
    "repertoire, emitter_state, keys = map_elites.get_distributed_init_fn(\n",
    "    devices=devices, centroids=centroids\n",
    ")(genotypes=training_states, random_key=keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_fn = map_elites.get_distributed_update_fn(\n",
    "    num_iterations=log_period, devices=devices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_step_multiplier = (\n",
    "    (pg_population_size_per_device + ga_population_size_per_device)\n",
    "    * eval_env_batch_size\n",
    "    * episode_length\n",
    "    + num_training_steps * pg_population_size_per_device\n",
    ") * num_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_metrics = {}\n",
    "repertoires = []\n",
    "\n",
    "for i in tqdm(range(num_iterations // log_period), total=num_iterations // log_period):\n",
    "    start_time = time.time()\n",
    "\n",
    "    repertoire, emitter_state, keys, metrics = update_fn(\n",
    "        repertoire, emitter_state, keys\n",
    "    )\n",
    "    metrics_cpu = jax.tree_map(lambda x: jax.device_get(x)[0], metrics)\n",
    "    timelapse = time.time() - start_time\n",
    "\n",
    "    # log metrics\n",
    "    for key, value in metrics_cpu.items():\n",
    "        # take all values\n",
    "        if key in all_metrics.keys():\n",
    "            all_metrics[key] = jnp.concatenate([all_metrics[key], value])\n",
    "        else:\n",
    "            all_metrics[key] = value\n",
    "\n",
    "    if i % save_repertoire_freq == 0:\n",
    "        repertoires.append(jax.tree_map(lambda x: jax.device_get(x)[0], repertoire))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_steps = (jnp.arange(num_iterations * log_period) + 1) * env_step_multiplier\n",
    "\n",
    "# create the plots and the grid\n",
    "fig, axes = plot_map_elites_results(\n",
    "    env_steps=env_steps,\n",
    "    metrics=all_metrics,\n",
    "    repertoire=repertoires[-1],\n",
    "    min_bd=min_bd,\n",
    "    max_bd=max_bd,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_repertoires = len(repertoires)\n",
    "num_cols = 5\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=math.ceil(num_repertoires / num_cols), ncols=num_cols, figsize=(30, 30)\n",
    ")\n",
    "for i, repertoire in enumerate(repertoires):\n",
    "\n",
    "    col_i = i % num_cols\n",
    "    row_i = i // num_cols\n",
    "\n",
    "    plot_2d_map_elites_repertoire(\n",
    "        centroids=centroids,\n",
    "        # repertoire_fitnesses=repertoire.fitnesses,\n",
    "        repertoire_fitnesses=jnp.where(\n",
    "            repertoire.fitnesses > -jnp.inf,\n",
    "            repertoire.genotypes.expl_noise,\n",
    "            -jnp.inf * jnp.ones_like(repertoire.fitnesses),\n",
    "        ),\n",
    "        minval=min_bd,\n",
    "        maxval=max_bd,\n",
    "        ax=axes[row_i, col_i],\n",
    "    )\n",
    "    axes[row_i, col_i].set_title(f\"Grid after {env_step_multiplier * i} steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ae46cf6a59eb5e192bc4f27fbb5c33d8a30eb9acb43edbb510eeaf7c819ab64"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
