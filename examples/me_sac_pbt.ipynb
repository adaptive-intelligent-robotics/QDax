{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "try:\n",
    "    import qdax\n",
    "except:\n",
    "    print(\"QDax not found. Installing...\")\n",
    "    !pip install qdax[cuda12]\n",
    "    import qdax\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import optax\n",
    "from brax.v1.io import html\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm\n",
    "\n",
    "from qdax import environments\n",
    "from qdax.baselines.sac_pbt import PBTSAC, PBTSacConfig, PBTSacTrainingState\n",
    "from qdax.core.containers.mapelites_repertoire import compute_cvt_centroids\n",
    "from qdax.core.distributed_map_elites import DistributedMAPElites\n",
    "from qdax.core.emitters.pbt_me_emitter import PBTEmitter, PBTEmitterConfig\n",
    "from qdax.core.emitters.pbt_variation_operators import sac_pbt_variation_fn\n",
    "from qdax.custom_types import Descriptor, ExtraScores, Fitness, Genotype, RNGKey\n",
    "from qdax.utils.metrics import CSVLogger, default_qd_metrics\n",
    "from qdax.utils.plotting import plot_map_elites_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_platform_name\", \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get devices (change gpu by tpu if needed)\n",
    "devices = jax.devices('gpu')\n",
    "num_devices = len(devices)\n",
    "print(f\"Detected the following {num_devices} device(s): {devices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"anttrap\"\n",
    "\n",
    "seed = 0\n",
    "\n",
    "# SAC config\n",
    "batch_size = 256\n",
    "episode_length = 1000\n",
    "tau = 0.005\n",
    "alpha_init = 1.0\n",
    "critic_hidden_layer_size = (256, 256) \n",
    "policy_hidden_layer_size = (256, 256) \n",
    "fix_alpha = False\n",
    "normalize_observations = False\n",
    "\n",
    "# Emitter config\n",
    "buffer_size = 100000\n",
    "pg_population_size_per_device = 10\n",
    "ga_population_size_per_device = 30\n",
    "num_training_iterations = 10000\n",
    "env_batch_size = 250\n",
    "grad_updates_per_step = 1.0\n",
    "iso_sigma = 0.005\n",
    "line_sigma = 0.05\n",
    "\n",
    "fraction_best_to_replace_from = 0.1\n",
    "fraction_to_replace_from_best = 0.2\n",
    "fraction_to_replace_from_samples = 0.4\n",
    "\n",
    "eval_env_batch_size = 1\n",
    "\n",
    "# MAP-Elites config\n",
    "num_init_cvt_samples = 50000\n",
    "num_centroids = 128\n",
    "log_period = 1\n",
    "num_loops = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Initialize environments\n",
    "env = environments.create(\n",
    "    env_name=env_name,\n",
    "    batch_size=env_batch_size * pg_population_size_per_device,\n",
    "    episode_length=episode_length,\n",
    "    auto_reset=True,\n",
    ")\n",
    "\n",
    "eval_env = environments.create(\n",
    "    env_name=env_name,\n",
    "    batch_size=eval_env_batch_size,\n",
    "    episode_length=episode_length,\n",
    "    auto_reset=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bd, max_bd = env.behavior_descriptor_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "key = jax.random.PRNGKey(seed)\n",
    "key, subkey = jax.random.split(key)\n",
    "env_states = jax.jit(env.reset)(rng=subkey)\n",
    "eval_env_first_states = jax.jit(eval_env.reset)(rng=subkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get agent\n",
    "config = PBTSacConfig(\n",
    "    batch_size=batch_size,\n",
    "    episode_length=episode_length,\n",
    "    tau=tau,\n",
    "    normalize_observations=normalize_observations,\n",
    "    alpha_init=alpha_init,\n",
    "    critic_hidden_layer_size=critic_hidden_layer_size,\n",
    "    policy_hidden_layer_size=policy_hidden_layer_size,\n",
    "    fix_alpha=fix_alpha,\n",
    ")\n",
    "\n",
    "agent = PBTSAC(config=config, action_size=env.action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init emitter\n",
    "emitter_config = PBTEmitterConfig(\n",
    "    buffer_size=buffer_size,\n",
    "    num_training_iterations=num_training_iterations // env_batch_size,\n",
    "    env_batch_size=env_batch_size,\n",
    "    grad_updates_per_step=grad_updates_per_step,\n",
    "    pg_population_size_per_device=pg_population_size_per_device,\n",
    "    ga_population_size_per_device=ga_population_size_per_device,\n",
    "    num_devices=num_devices,\n",
    "    fraction_best_to_replace_from=fraction_best_to_replace_from,\n",
    "    fraction_to_replace_from_best=fraction_to_replace_from_best,\n",
    "    fraction_to_replace_from_samples=fraction_to_replace_from_samples,\n",
    "    fraction_sort_exchange=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_fn = functools.partial(\n",
    "    sac_pbt_variation_fn, iso_sigma=iso_sigma, line_sigma=line_sigma\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emitter = PBTEmitter(\n",
    "    pbt_agent=agent,\n",
    "    config=emitter_config,\n",
    "    env=env,\n",
    "    variation_fn=variation_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get scoring function\n",
    "bd_extraction_fn = environments.behavior_descriptor_extractor[env_name]\n",
    "eval_policy = agent.get_eval_qd_fn(eval_env, bd_extraction_fn=bd_extraction_fn)\n",
    "\n",
    "\n",
    "def scoring_function(genotypes, random_key):\n",
    "    population_size = jax.tree_util.tree_leaves(genotypes)[0].shape[0]\n",
    "    first_states = jax.tree_map(\n",
    "        lambda x: jnp.expand_dims(x, axis=0), eval_env_first_states\n",
    "    )\n",
    "    first_states = jax.tree_map(\n",
    "        lambda x: jnp.repeat(x, population_size, axis=0), first_states\n",
    "    )\n",
    "    population_returns, population_bds, _, _ = eval_policy(genotypes, first_states)\n",
    "    return population_returns, population_bds, {}, random_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get minimum reward value to make sure qd_score are positive\n",
    "reward_offset = environments.reward_offset[env_name]\n",
    "\n",
    "# Define a metrics function\n",
    "metrics_function = functools.partial(\n",
    "    default_qd_metrics,\n",
    "    qd_offset=reward_offset * episode_length,\n",
    ")\n",
    "\n",
    "# Get the MAP-Elites algorithm\n",
    "map_elites = DistributedMAPElites(\n",
    "    scoring_function=scoring_function,\n",
    "    emitter=emitter,\n",
    "    metrics_function=metrics_function,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "centroids, key = compute_cvt_centroids(\n",
    "    num_descriptors=env.behavior_descriptor_length,\n",
    "    num_init_cvt_samples=num_init_cvt_samples,\n",
    "    num_centroids=num_centroids,\n",
    "    minval=min_bd,\n",
    "    maxval=max_bd,\n",
    "    random_key=key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, *keys = jax.random.split(key, num=1 + num_devices)\n",
    "keys = jnp.stack(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# get the initial training states and replay buffers\n",
    "agent_init_fn = agent.get_init_fn(\n",
    "    population_size=pg_population_size_per_device + ga_population_size_per_device,\n",
    "    action_size=env.action_size,\n",
    "    observation_size=env.observation_size,\n",
    "    buffer_size=buffer_size,\n",
    ")\n",
    "keys, training_states, _ = jax.pmap(agent_init_fn, axis_name=\"p\", devices=devices)(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# empty optimizers states to avoid too heavy repertories\n",
    "training_states = jax.pmap(\n",
    "    jax.vmap(training_states.__class__.empty_optimizers_states),\n",
    "    axis_name=\"p\",\n",
    "    devices=devices,\n",
    ")(training_states)\n",
    "\n",
    "# initialize map-elites\n",
    "repertoire, emitter_state, keys = map_elites.get_distributed_init_fn(\n",
    "    devices=devices, centroids=centroids\n",
    ")(genotypes=training_states, random_key=keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_fn = map_elites.get_distributed_update_fn(\n",
    "    num_iterations=log_period, devices=devices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_step_multiplier = (\n",
    "    (pg_population_size_per_device + ga_population_size_per_device)\n",
    "    * eval_env_batch_size\n",
    "    * episode_length\n",
    "    + num_training_iterations * pg_population_size_per_device\n",
    ") * num_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_metrics = {}\n",
    "\n",
    "for i in tqdm(range(num_loops // log_period), total=num_loops // log_period):\n",
    "    start_time = time.time()\n",
    "\n",
    "    repertoire, emitter_state, keys, metrics = update_fn(\n",
    "        repertoire, emitter_state, keys\n",
    "    )\n",
    "    metrics_cpu = jax.tree_map(\n",
    "        lambda x: jax.device_put(x, jax.devices(\"cpu\")[0])[0], metrics\n",
    "    )\n",
    "    timelapse = time.time() - start_time\n",
    "\n",
    "    # log metrics\n",
    "    for key, value in metrics_cpu.items():\n",
    "        # take all values\n",
    "        if key in all_metrics.keys():\n",
    "            all_metrics[key] = jnp.concatenate([all_metrics[key], value])\n",
    "        else:\n",
    "            all_metrics[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the performance evolution plots and visualize final grid\n",
    "repertoire_cpu = jax.tree_map(\n",
    "    lambda x: jax.device_put(x, jax.devices(\"cpu\")[0])[0], repertoire\n",
    ")\n",
    "env_steps = (jnp.arange(num_loops) + 1) * env_step_multiplier\n",
    "\n",
    "fig, axes = plot_map_elites_results(\n",
    "    env_steps=env_steps,\n",
    "    metrics=all_metrics,\n",
    "    repertoire=repertoire_cpu,\n",
    "    min_bd=min_bd,\n",
    "    max_bd=max_bd,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize learnt behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate best individual of the repertoire\n",
    "best_idx = jnp.argmax(repertoire_cpu.fitnesses)\n",
    "best_fitness = jnp.max(repertoire_cpu.fitnesses)\n",
    "best_bd = repertoire_cpu.descriptors[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repertoire_cpu.descriptors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate agent that goes the further on the y-axis\n",
    "# best_idx = jnp.argmax(repertoire.descriptors[:, 0])\n",
    "# best_fitness = repertoire.fitnesses[best_idx]\n",
    "# best_bd = repertoire.descriptors[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Fitness of the selected agent: {best_fitness:.2f}\\n\",\n",
    "    f\"Behavior descriptor of the selected agent: {best_bd}\\n\",\n",
    "    f\"Index in the repertoire of this individual: {best_idx}\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = environments.create(env_name, episode_length=episode_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_step_fn = jax.pmap(\n",
    "    functools.partial(agent.play_step_fn, env=env, deterministic=True, evaluation=True),\n",
    "    axis_name=\"p\",\n",
    "    devices=devices[:1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_state = jax.tree_util.tree_map(lambda x: x[best_idx], repertoire_cpu.genotypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rollout = []\n",
    "\n",
    "rng = jax.random.PRNGKey(seed=1)\n",
    "env_state = jax.jit(env.reset)(rng=rng)\n",
    "\n",
    "training_state, env_state = jax.tree_map(\n",
    "    lambda x: jnp.expand_dims(x, axis=0), (training_state, env_state)\n",
    ")\n",
    "\n",
    "for _ in range(episode_length):\n",
    "\n",
    "    rollout.append(env_state)\n",
    "    env_state, training_state, _ = play_step_fn(env_state, training_state)\n",
    "\n",
    "print(f\"The trajectory of this individual contains {len(rollout)} transitions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout = [\n",
    "    jax.tree_map(lambda x: jax.device_put(x[0], jax.devices(\"cpu\")[0]), env_state)\n",
    "    for env_state in rollout\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(html.render(env.sys, [s.qp for s in rollout[:episode_length]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('3.9.2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "1508da3da994e8b4133db52fbfc99c200ce19b8717cb4612fe84174533968534"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
