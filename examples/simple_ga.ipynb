{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b46c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Tuple, Type\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import functools\n",
    "\n",
    "from qdax.baselines.genetic_algorithm import GeneticAlgorithm\n",
    "\n",
    "from qdax.core.neuroevolution.buffers.buffer import QDTransition\n",
    "from qdax.core.neuroevolution.networks.networks import MLP\n",
    "\n",
    "from qdax.core.emitters.mutation_operators import (\n",
    "    polynomial_crossover,\n",
    "    polynomial_mutation,\n",
    ")\n",
    "from qdax.core.emitters.standard_emitters import MixingEmitter\n",
    "from qdax.types import ExtraScores, Fitness, RNGKey, Descriptor\n",
    "from qdax.utils.metrics import default_ga_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd1e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "policy_hidden_layer_sizes = (64, 64)\n",
    "\n",
    "episode_length = 100\n",
    "\n",
    "population_size = 1000\n",
    "num_iterations = 10000\n",
    "proportion_mutation = 0.80\n",
    "proportion_var_to_change = 0.5\n",
    "proportion_to_mutate = 0.5\n",
    "eta = 0.05\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a842cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jumanji\n",
    "\n",
    "# Instantiate a Jumanji environment using the registry\n",
    "env = jumanji.make('Snake-6x6-v0')\n",
    "\n",
    "# Reset your (jit-able) environment\n",
    "key = jax.random.PRNGKey(0)\n",
    "state, timestep = jax.jit(env.reset)(key)\n",
    "\n",
    "# (Optional) Render the env state\n",
    "# env.render(state)\n",
    "\n",
    "# Interact with the (jit-able) environment\n",
    "action = env.action_spec().generate_value()          # Action selection (dummy value here)\n",
    "state, timestep = jax.jit(env.step)(state, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ecb4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_spec().maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3743da50",
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.ravel(timestep.observation).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15c6a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.prod(jnp.array(env.observation_spec().shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac82f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def observation_processing(observation):\n",
    "    network_input = jnp.ravel(observation)\n",
    "    return network_input\n",
    "\n",
    "\n",
    "def play_step_fn(\n",
    "    env_state,\n",
    "    timestep,\n",
    "    policy_params,\n",
    "    random_key,\n",
    "):\n",
    "    \"\"\"\n",
    "    Play an environment step and return the updated state and the transition.\n",
    "    \"\"\"\n",
    "\n",
    "    network_input = observation_processing(timestep.observation)\n",
    "\n",
    "    proba_action = policy_network.apply(policy_params, network_input)\n",
    "\n",
    "    action = jax.random.choice(\n",
    "        key=random_key,\n",
    "        a=num_ems * num_items,\n",
    "        p=proba_action,\n",
    "    )\n",
    "\n",
    "    state_desc = None\n",
    "    next_state, next_timestep, extras = env.step(env_state, action)\n",
    "\n",
    "    # next_state_desc=next_state.info[\"state_descriptor\"]\n",
    "    next_state_desc = None\n",
    "\n",
    "    transition = QDTransition(\n",
    "        obs=timestep.observation,\n",
    "        next_obs=next_timestep.observation,\n",
    "        rewards=next_timestep.reward,\n",
    "        dones=jnp.where(next_timestep.last(), x=jnp.array(1), y=jnp.array(0)),\n",
    "        actions=action,\n",
    "        # truncations=next_state.info[\"truncation\"],\n",
    "        # TODO: fix this\n",
    "        truncations=jnp.array(0),\n",
    "        state_desc=state_desc,\n",
    "        next_state_desc=next_state_desc,\n",
    "    )\n",
    "\n",
    "    # print(\"Look at this transition dones: \", transition.dones)\n",
    "    # print(\"Look at this transition rewards: \", transition.rewards)\n",
    "\n",
    "    return next_state, next_timestep, policy_params, random_key, transition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd2065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init a random key\n",
    "random_key = jax.random.PRNGKey(seed)\n",
    "\n",
    "# Init policy network\n",
    "\n",
    "# interesting code from BinPackRandomAgent\n",
    "num_actions = env.action_spec().maximum + 1\n",
    "\n",
    "policy_layer_sizes = policy_hidden_layer_sizes + (num_actions,)\n",
    "policy_network = MLP(\n",
    "    layer_sizes=policy_layer_sizes,\n",
    "    kernel_init=jax.nn.initializers.lecun_uniform(),\n",
    "    final_activation=jax.nn.softmax,\n",
    ")\n",
    "\n",
    "# Init population of controllers\n",
    "random_key, subkey = jax.random.split(random_key)\n",
    "keys = jax.random.split(subkey, num=batch_size)\n",
    "\n",
    "# TODO: need to compute observation size from observation spec\n",
    "\n",
    "# start by giving concat of ems and items\n",
    "obs_spec = env.observation_spec()\n",
    "\n",
    "import numpy as np\n",
    "observation_size = np.prod(np.array(env.observation_spec().shape))\n",
    "\n",
    "fake_batch = jnp.zeros(shape=(batch_size, observation_size))\n",
    "init_variables = jax.vmap(policy_network.init)(keys, fake_batch)\n",
    "\n",
    "\n",
    "# Create the initial environment states\n",
    "random_key, subkey = jax.random.split(random_key)\n",
    "keys = jnp.repeat(jnp.expand_dims(subkey, axis=0), repeats=batch_size, axis=0)\n",
    "reset_fn = jax.jit(jax.vmap(env.reset))\n",
    "init_states, init_timesteps = reset_fn(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a264b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the scoring function\n",
    "def bd_extraction_fn(data: QDTransition, mask: jnp.ndarray) -> Descriptor:\n",
    "    \"\"\"Compute feet contact time proportion.\n",
    "\n",
    "    This function suppose that state descriptor is the feet contact, as it\n",
    "    just computes the mean of the state descriptors given.\n",
    "    \"\"\"\n",
    "    # reshape mask for bd extraction\n",
    "    mask = jnp.expand_dims(mask, axis=-1)\n",
    "\n",
    "    observation = jax.vmap(observation_processing)(data.obs)\n",
    "    N = observation.shape[-1]\n",
    "\n",
    "    # print(\"Processed observation in bd extract fn: \", observation)\n",
    "\n",
    "    # print(\"Chelou : \", jnp.arange(start=0, stop=N // 2))\n",
    "    # value1 = jnp.multiply(\n",
    "    #     observation[..., : (N // 2)],\n",
    "    #     jnp.array(1 / N) * jnp.arange(start=0, stop=N // 2),\n",
    "    # )\n",
    "    # value2 = jnp.multiply(\n",
    "    #     observation[..., (N // 2) :],\n",
    "    #     jnp.array(1 / N) * jnp.arange(start=0, stop=(N - (N // 2))),\n",
    "    # )\n",
    "    desc1 = jnp.mean(observation[..., : (N // 2)], axis=1, keepdims=True)\n",
    "    desc2 = jnp.mean(observation[..., (N // 2) :], axis=1, keepdims=True)\n",
    "\n",
    "    # print(\"descriptor 1: \", desc1)\n",
    "    # print(\"descriptor 2: \", desc2)\n",
    "\n",
    "    # Get behavior descriptor\n",
    "    descriptors = jnp.concatenate([desc1, desc2], axis=1)\n",
    "\n",
    "    return descriptors\n",
    "\n",
    "\n",
    "# bd_extraction_fn = environments.behavior_descriptor_extractor[env_name]\n",
    "scoring_fn = functools.partial(\n",
    "    scoring_function,\n",
    "    init_states=init_states,\n",
    "    init_timesteps=init_timesteps,\n",
    "    episode_length=episode_length,\n",
    "    play_step_fn=play_step_fn,\n",
    "    behavior_descriptor_extractor=bd_extraction_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b77d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_fn(\n",
    "    genotypes: jnp.ndarray, random_key: RNGKey\n",
    ") -> Tuple[Fitness, ExtraScores, RNGKey]:\n",
    "    fitnesses, _ = scoring_function(genotypes)\n",
    "    return fitnesses, {}, random_key\n",
    "\n",
    "# initial population\n",
    "random_key = jax.random.PRNGKey(42)\n",
    "random_key, subkey = jax.random.split(random_key)\n",
    "init_genotypes = jax.random.uniform(\n",
    "    subkey,\n",
    "    (batch_size, genotype_dim),\n",
    "    minval=minval,\n",
    "    maxval=maxval,\n",
    "    dtype=jnp.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30061ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossover function\n",
    "crossover_function = partial(\n",
    "    polynomial_crossover, proportion_var_to_change=proportion_var_to_change\n",
    ")\n",
    "\n",
    "# mutation function\n",
    "mutation_function = partial(\n",
    "    polynomial_mutation,\n",
    "    eta=eta,\n",
    "    minval=minval,\n",
    "    maxval=maxval,\n",
    "    proportion_to_mutate=proportion_to_mutate,\n",
    ")\n",
    "\n",
    "# Define emitter\n",
    "mixing_emitter = MixingEmitter(\n",
    "    mutation_fn=mutation_function,\n",
    "    variation_fn=crossover_function,\n",
    "    variation_percentage=1 - proportion_mutation,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "algo_instance = GeneticAlgorithm(\n",
    "    scoring_function=scoring_fn,\n",
    "    emitter=mixing_emitter,\n",
    "    metrics_function=default_ga_metrics,\n",
    ")\n",
    "\n",
    "repertoire, emitter_state, random_key = algo_instance.init(\n",
    "    init_genotypes, population_size, random_key\n",
    ")\n",
    "\n",
    "# Run the algorithm\n",
    "(repertoire, emitter_state, random_key,), metrics = jax.lax.scan(\n",
    "    algo_instance.scan_update,\n",
    "    (repertoire, emitter_state, random_key),\n",
    "    (),\n",
    "    length=num_iterations,\n",
    ")\n",
    "\n",
    "x, y = metrics[\"max_fitness\"][-1]\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114ea4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a35bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5da301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f55aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
