{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "233e0f03",
   "metadata": {},
   "source": [
    "## Training a simple genetic algorithm on the Snake environment from Jumanji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3537f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b46c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Tuple, Type\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import jumanji\n",
    "\n",
    "import functools\n",
    "\n",
    "from qdax.baselines.genetic_algorithm import GeneticAlgorithm\n",
    "\n",
    "from qdax.core.neuroevolution.buffers.buffer import QDTransition\n",
    "from qdax.core.neuroevolution.networks.networks import MLP\n",
    "\n",
    "from qdax.tasks.jumanji_envs import jumanji_scoring_function\n",
    "\n",
    "from qdax.core.emitters.mutation_operators import isoline_variation\n",
    "\n",
    "from qdax.core.emitters.standard_emitters import MixingEmitter\n",
    "from qdax.types import ExtraScores, Fitness, RNGKey, Descriptor\n",
    "from qdax.utils.metrics import default_ga_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c2f1f7",
   "metadata": {},
   "source": [
    "## Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd1e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "policy_hidden_layer_sizes = (128, 128)\n",
    "\n",
    "episode_length = 1000\n",
    "\n",
    "population_size = 500\n",
    "batch_size = population_size\n",
    "\n",
    "num_iterations = 1000\n",
    "\n",
    "iso_sigma = 0.005\n",
    "line_sigma = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8c890a",
   "metadata": {},
   "source": [
    "## Instantiate the snake environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a842cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Jumanji environment using the registry\n",
    "env = jumanji.make('Snake-6x6-v0')\n",
    "\n",
    "# Reset your (jit-able) environment\n",
    "key = jax.random.PRNGKey(0)\n",
    "state, timestep = jax.jit(env.reset)(key)\n",
    "\n",
    "# (Optional) Render the env state\n",
    "# env.render(state)\n",
    "\n",
    "# Interact with the (jit-able) environment\n",
    "action = env.action_spec().generate_value()          # Action selection (dummy value here)\n",
    "state, timestep = jax.jit(env.step)(state, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ecb4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_spec().num_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3743da50",
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.ravel(timestep.observation).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15c6a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.prod(jnp.array(env.observation_spec().shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac82f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def observation_processing(observation):\n",
    "    network_input = jnp.ravel(observation)\n",
    "    return network_input\n",
    "\n",
    "\n",
    "def play_step_fn(\n",
    "    env_state,\n",
    "    timestep,\n",
    "    policy_params,\n",
    "    random_key,\n",
    "):\n",
    "    \"\"\"\n",
    "    Play an environment step and return the updated state and the transition.\n",
    "    \"\"\"\n",
    "\n",
    "    network_input = observation_processing(timestep.observation)\n",
    "\n",
    "    proba_action = policy_network.apply(policy_params, network_input)\n",
    "\n",
    "    action = jax.random.choice(\n",
    "        key=random_key,\n",
    "        a=proba_action.shape[0],\n",
    "        p=proba_action,\n",
    "    )\n",
    "\n",
    "    state_desc = None\n",
    "    next_state, next_timestep = env.step(env_state, action)\n",
    "\n",
    "    # next_state_desc=next_state.info[\"state_descriptor\"]\n",
    "    next_state_desc = None\n",
    "\n",
    "    transition = QDTransition(\n",
    "        obs=timestep.observation,\n",
    "        next_obs=next_timestep.observation,\n",
    "        rewards=next_timestep.reward,\n",
    "        dones=jnp.where(next_timestep.last(), x=jnp.array(1), y=jnp.array(0)),\n",
    "        actions=action,\n",
    "        # truncations=next_state.info[\"truncation\"],\n",
    "        # TODO: fix this\n",
    "        truncations=jnp.array(0),\n",
    "        state_desc=state_desc,\n",
    "        next_state_desc=next_state_desc,\n",
    "    )\n",
    "\n",
    "    # print(\"Look at this transition dones: \", transition.dones)\n",
    "    # print(\"Look at this transition rewards: \", transition.rewards)\n",
    "\n",
    "    return next_state, next_timestep, policy_params, random_key, transition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd2065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init a random key\n",
    "random_key = jax.random.PRNGKey(seed)\n",
    "\n",
    "# Init policy network\n",
    "\n",
    "# interesting code from BinPackRandomAgent\n",
    "num_actions = env.action_spec().maximum + 1\n",
    "\n",
    "policy_layer_sizes = policy_hidden_layer_sizes + (num_actions,)\n",
    "policy_network = MLP(\n",
    "    layer_sizes=policy_layer_sizes,\n",
    "    kernel_init=jax.nn.initializers.lecun_uniform(),\n",
    "    final_activation=jax.nn.softmax,\n",
    ")\n",
    "\n",
    "# Init population of controllers\n",
    "random_key, subkey = jax.random.split(random_key)\n",
    "keys = jax.random.split(subkey, num=batch_size)\n",
    "\n",
    "# TODO: need to compute observation size from observation spec\n",
    "\n",
    "# start by giving concat of ems and items\n",
    "obs_spec = env.observation_spec()\n",
    "\n",
    "import numpy as np\n",
    "observation_size = np.prod(np.array(env.observation_spec().shape))\n",
    "\n",
    "fake_batch = jnp.zeros(shape=(batch_size, observation_size))\n",
    "init_variables = jax.vmap(policy_network.init)(keys, fake_batch)\n",
    "\n",
    "\n",
    "# Create the initial environment states\n",
    "random_key, subkey = jax.random.split(random_key)\n",
    "keys = jnp.repeat(jnp.expand_dims(subkey, axis=0), repeats=batch_size, axis=0)\n",
    "reset_fn = jax.jit(jax.vmap(env.reset))\n",
    "init_states, init_timesteps = reset_fn(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a264b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the scoring function\n",
    "def bd_extraction(data: QDTransition, mask: jnp.ndarray, linear_projection: jnp.array) -> Descriptor:\n",
    "    \"\"\"Compute feet contact time proportion.\n",
    "\n",
    "    This function suppose that state descriptor is the feet contact, as it\n",
    "    just computes the mean of the state descriptors given.\n",
    "    \"\"\"\n",
    "    # reshape mask for bd extraction\n",
    "    mask = jnp.expand_dims(mask, axis=-1)\n",
    "\n",
    "    observation = jax.vmap(observation_processing)(data.obs)\n",
    "    N = observation.shape[-1]\n",
    "\n",
    "    mean_observation = jnp.mean(observation, axis=-1)\n",
    "    behavior_descriptor = jnp.tanh(mean_observation @ linear_projection.T)\n",
    "    \n",
    "    # Get behavior descriptor\n",
    "    descriptors = jnp.concatenate([desc1, desc2], axis=1)\n",
    "\n",
    "    return descriptors\n",
    "\n",
    "random_key, subkey = jax.random.split(random_key)\n",
    "linear_projection = jax.random.uniform(\n",
    "    random_key, (2, observation_size), minval=-1, maxval=1, dtype=jnp.float32\n",
    ")\n",
    "\n",
    "bd_extraction_fn = functools.partial(\n",
    "    bd_extraction,\n",
    "    linear_projection=linear_projection\n",
    ")\n",
    "\n",
    "# bd_extraction_fn = environments.behavior_descriptor_extractor[env_name]\n",
    "scoring_fn = functools.partial(\n",
    "    jumanji_scoring_function,\n",
    "    init_states=init_states,\n",
    "    init_timesteps=init_timesteps,\n",
    "    episode_length=episode_length,\n",
    "    play_step_fn=play_step_fn,\n",
    "    behavior_descriptor_extractor=bd_extraction_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b77d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_function(\n",
    "    genotypes: jnp.ndarray, random_key: RNGKey\n",
    ") -> Tuple[Fitness, ExtraScores, RNGKey]:\n",
    "    fitnesses, _, extra_scores, random_key = scoring_fn(genotypes, random_key)\n",
    "    return fitnesses.reshape(-1, 1), extra_scores, random_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30061ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define emitter\n",
    "variation_fn = functools.partial(\n",
    "    isoline_variation, iso_sigma=iso_sigma, line_sigma=line_sigma\n",
    ")\n",
    "mixing_emitter = MixingEmitter(\n",
    "    mutation_fn=None, \n",
    "    variation_fn=variation_fn, \n",
    "    variation_percentage=1.0, \n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "algo_instance = GeneticAlgorithm(\n",
    "    scoring_function=scoring_function,\n",
    "    emitter=mixing_emitter,\n",
    "    metrics_function=default_ga_metrics,\n",
    ")\n",
    "\n",
    "repertoire, emitter_state, random_key = algo_instance.init(\n",
    "    init_variables, population_size, random_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1af3a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Run the algorithm\n",
    "(repertoire, emitter_state, random_key,), metrics = jax.lax.scan(\n",
    "    algo_instance.scan_update,\n",
    "    (repertoire, emitter_state, random_key),\n",
    "    (),\n",
    "    length=num_iterations,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114ea4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[\"max_fitness\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a35bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "repertoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5da301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93d8154e",
   "metadata": {},
   "source": [
    "## Play snake with the best policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a24856f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff882f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = jnp.argmax(repertoire.fitnesses)\n",
    "best_fitness = jnp.max(repertoire.fitnesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Best fitness in the repertoire: {best_fitness:.2f}\\n\",\n",
    "    f\"Index in the repertoire of this individual: {best_idx}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07523e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_params = jax.tree_util.tree_map(\n",
    "    lambda x: x[best_idx],\n",
    "    repertoire.genotypes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75ce088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a03409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset your (jit-able) environment\n",
    "key = jax.random.PRNGKey(0)\n",
    "state, timestep = jax.jit(env.reset)(key)\n",
    "\n",
    "for _ in range(100):\n",
    "    # (Optional) Render the env state\n",
    "    env.render(state)\n",
    "\n",
    "    # Interact with the (jit-able) environment\n",
    "    \n",
    "    \n",
    "    network_input = observation_processing(timestep.observation)\n",
    "\n",
    "    proba_action = policy_network.apply(my_params, network_input)\n",
    "\n",
    "    action = jax.random.choice(\n",
    "        key=random_key,\n",
    "        a=proba_action.shape[0],\n",
    "        p=proba_action,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    state, timestep = jax.jit(env.step)(state, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daca8bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc09b408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80754733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7933284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b475997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
